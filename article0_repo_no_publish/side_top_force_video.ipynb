{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create video with plot visualization of force trajectory over time.\n",
    "1. Video of top and side views with tracking of the pendulum rod tip.\n",
    "2. Contact point of the stem along the rod- in side view.\n",
    "3. visualization of force trajectory over time (with deflection, angle, and contact as well?).\n",
    "4. maybe add an arrow of the Fxy direction in the top view video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "c:\\Users\\Amir\\Documents\\PHD\\Python\\GitHub\\Amir_Repositories\\Repo_article0\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "# generic\n",
    "import sys\n",
    "import numpy as np\n",
    "import os,glob # for listing files in folder\n",
    "import re # regular expressions\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn\n",
    "import math as m\n",
    "import cv2\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial import distance as sci_distance\n",
    "from scipy.stats import kruskal\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.lines as mlines\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# custom\n",
    "import article0_funcs_clean # writch to updated exp2 functions\n",
    "# sys.path.append('..')\n",
    "import useful_functions as uf \n",
    "\n",
    "#general parameters\n",
    "cmap = plt.get_cmap('viridis')\n",
    "fs = 16 # standard font size for plots\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "importlib.reload(uf)\n",
    "importlib.reload(article0_funcs_clean)\n",
    "\n",
    "save_folder = r'C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Images'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "root_path = r'C:\\Users\\Amir\\Documents\\PHD\\Experiments\\Force Measurements'\n",
    "basepath = root_path+r'\\Exp2_Pendulum' # pendulum exp folder\n",
    "# excel_csv= r'\\Exp2_supplementary_measurements_events.csv'\n",
    "data_excel = r'\\Exp2_supplementary_measurements_events_xl.xlsx'\n",
    "\n",
    "# straw exp data\n",
    "# data_panda = pd.read_csv(basepath+excel_csv)\n",
    "data_panda = pd.read_excel(basepath+data_excel)\n",
    "\n",
    "\n",
    "# import tracked data, initiate variables\n",
    "track_sup_path = r'\\track_logs'\n",
    "track_folder_path = basepath+track_sup_path\n",
    "\n",
    "track_contact_path = r'\\contact_track_logs'\n",
    "contact_folder_path = basepath+track_contact_path\n",
    "\n",
    "# track_near_sup_path = r'\\twine_init_logs'\n",
    "# track_near_sup_folder_path = basepath+track_near_sup_path\n",
    "\n",
    "# h5_path = r'\\Measurements\\root_stem_results'\n",
    "# h5_folder_path = basepath+h5_path\n",
    "\n",
    "# E_path = r'\\Young_moduli'\n",
    "# E_folder_path = basepath+E_path\n",
    "\n",
    "N_track = len(os.listdir(track_folder_path)) # get number of files in track folder\n",
    "N_contact=len(os.listdir(contact_folder_path)) # get number of files in contact folder\n",
    "N_tot = len(data_panda) # get number of lines in excel\n",
    "# N_E = len(os.listdir(E_folder_path))\n",
    "\n",
    "\n",
    "#%% remove problematic events from raw data\n",
    "delete_rows = [] # save rows to delete\n",
    "problem_exp = [] # exp_num of problem events\n",
    "\n",
    "for i in range(N_tot): # remove problem events and non-Helda events\n",
    "    if data_panda.at[i,'problem']!='na' or data_panda.at[i,'Bean_Strain']!='Helda':\n",
    "        delete_rows.append(i)\n",
    "        problem_exp.append(data_panda.at[i,'Exp_num'])\n",
    "N = N_tot - len(delete_rows) # modify num of rows\n",
    "\n",
    "data_panda = data_panda.drop(data_panda.index[delete_rows]) # remove prob. events\n",
    "data_panda = data_panda.reset_index() # redo index\n",
    "#%% get misc. file lists\n",
    "\n",
    "# get track files for support bottom coordinates\n",
    "remove_chars = re.compile('[,_\\.!?]') # what to remove from strings\n",
    "track_dict = {} # save support track in dictionary by exp and events\n",
    "i=0 # start with first track file\n",
    "for file in glob.glob(os.path.join(track_folder_path, '*.txt')): # for each event:\n",
    "    exp = int(re.findall('_\\d{3,4}_',file)[0].replace('_','')) # find exp number (3-4 digits)\n",
    "    event = int(re.findall('[0-9]',re.findall('_\\d{1}\\D',file)[0].replace('_',''))[0]) # find event number\n",
    "    viewt = re.findall('(side{1}|top{1})',file)[0] #.replace('_','')\n",
    "    track_dict[(exp,event,viewt)] = [file] # add new exp\n",
    "    i+=1\n",
    "\n",
    "# get track files for stem-support contact coordinates\n",
    "contact_dict = {} # save support contact track in dictionary by exp and events\n",
    "i=0 # start with first contact file\n",
    "for file in glob.glob(os.path.join(contact_folder_path, '*.txt')): # for each event:\n",
    "    exp = int(re.findall('_\\d{3,4}_',file)[0].replace('_','')) # find exp number (3-4 digits)\n",
    "    event = int(re.findall('_[0-9]_',file)[0].replace('_','')) # find event number\n",
    "    contact_dict[(exp,event)] = [file] # add new exp\n",
    "    i+=1\n",
    "\n",
    "# get track files for 2 stem positions on either side of support\n",
    "# near_sup_track_dict = {}\n",
    "# i=0 # start with first stem_near_sup file\n",
    "# for file in glob.glob(os.path.join(track_near_sup_folder_path, '*.txt')): # for each event:\n",
    "#     exp = int(re.findall('_\\d{3,4}_',file)[0].replace('_','')) # find exp number (3-4 digits)\n",
    "#     event = int(re.findall('_[0-9]_',file)[0].replace('_','')) # find event number\n",
    "#     near_sup_track_dict[(exp,event)] = [file] # add new exp\n",
    "#     i+=1\n",
    "\n",
    "# get h5 files for stem near support\n",
    "# h5_dict = {}\n",
    "# i=0 # start with first h5 file\n",
    "# for file in glob.glob(os.path.join(h5_folder_path, '*.h5')): # for each event:\n",
    "#     exp = int(re.findall('interekt_\\d{2,3}_',file)[0].split('_')[1]) # find exp number (3-4 digits)\n",
    "#     event = int(re.findall('e_[0-9]_',file)[0].split('_')[1]) # find event number\n",
    "#     start_frame = int(re.findall('_\\d{2,5}-\\d{2,5}',file)[0].replace('_','').split('-')[0]) # find start frame\n",
    "#     h5_dict[(exp,event,start_frame)] = [file] # add new exp\n",
    "#     i+=1\n",
    "\n",
    "# get Young modulus files\n",
    "# E_dict = {}\n",
    "# for file in glob.glob(os.path.join(E_folder_path, '*.csv')):\n",
    "#     exp = int(re.findall('\\d{2,3}',file)[0])\n",
    "#     E_dict[exp]=pd.read_csv(file,header=None)\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear plants and events\n",
    "plants = []\n",
    "events = []\n",
    "#%% populate plant and event instances\n",
    "i = 0\n",
    "N = len(data_panda)\n",
    "for i in tqdm(range(N)): # N\n",
    "    try:\n",
    "        exp = int(re.findall('\\d{3,4}',data_panda.at[i,'Exp_num'])[0]) # exp num\n",
    "        view = data_panda.at[i,'View']  # side of top view\n",
    "        if view == 'top':\n",
    "            plants[-1].pix2cm_t = float(data_panda.at[i,'Top_pix2cm'])\n",
    "\n",
    "        if i==0 or exp!=plants[-1].exp_num: # append new plant with data from pandas\n",
    "            #basic data\n",
    "            plants.append(article0_funcs_clean.Plant(data_panda,basepath,i,exp))\n",
    "            # view dependent data\n",
    "            plants[-1].view_data(data_panda,i)\n",
    "            # circumnutation data\n",
    "            plants[-1].cn_data(data_panda,i)\n",
    "            #Youngs modulus by segment with avg\n",
    "            # plants[-1].getE(E_dict)\n",
    "\n",
    "\n",
    "        event =  int(re.findall('_[0-9]',data_panda.at[i,\n",
    "        'Exp_num'])[0].replace('_','')) # get event number\n",
    "\n",
    "\n",
    "        # if this is the 1st event or the previous event_num is different from the current one:\n",
    "        # add new event to list\n",
    "        if len(events)==0 or events[-1].event_num != event or \\\n",
    "            events[-1].p.exp_num != exp:\n",
    "            events.append(article0_funcs_clean.Event(plants[-1],data_panda,i))\n",
    "        events[-1].event_num = event\n",
    "\n",
    "        # view dependent data\n",
    "        events[-1].view_data(data_panda,i,view)\n",
    "\n",
    "        # get automated extraction of twine(decision) time\n",
    "        # events[-1].get_twine_time(exp,event,view,\n",
    "        #                   h5_dict,near_sup_track_dict,50,track_dict,to_plot=0)\n",
    "\n",
    "\n",
    "        # get track data, select decision period data, pix2cm,\n",
    "        events[-1].event_base_calcs(view,track_dict,contact_dict)\n",
    "        # calc\n",
    "        events[-1].event_calc_variables(view)\n",
    "        # print(f'i={i}, exp number {exp}, {event}') # print progress\n",
    "    except Exception as e:\n",
    "        print(f'Error at i={i}, exp number {exp}, {event}')\n",
    "        print(e)\n",
    "        \n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check new measurements\n",
    "for i in range(len(events)):\n",
    "    events[i].support_base_z_pos_pix_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define create video of side and top view in split screen for a specific event\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "\n",
    "def parallel_video(images1, coords1, images2, coords2, fps=2, fixed_height=300):\n",
    "    \"\"\"\n",
    "    Display two sets of images side by side with markers in a resizable window.\n",
    "    \n",
    "    Parameters:\n",
    "        images1 (list): First set of images (file paths or image arrays).\n",
    "        coords1 (list): Coordinates for the first set of images (list of (x, y) tuples).\n",
    "        images2 (list): Second set of images (file paths or image arrays).\n",
    "        coords2 (list): Coordinates for the second set of images (list of (x, y) tuples).\n",
    "        fps (int): Frames per second for image display.\n",
    "        fixed_height (int): Fixed height of the final window.\n",
    "    \"\"\"\n",
    "    if len(images1) != len(coords1) or len(images2) != len(coords2):\n",
    "        raise ValueError(\"The number of images and coordinates must match for both sets.\")\n",
    "    if len(images1) != len(images2):\n",
    "        raise ValueError(\"Both sets of images must have the same length.\")\n",
    "    \n",
    "    delay = 1 / fps  # Delay in seconds between frames\n",
    "    \n",
    "    # Create a resizable window\n",
    "    window_name = \"Image Viewer\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    for idx, (img1, coord1, img2, coord2) in enumerate(zip(images1, coords1, images2, coords2)):\n",
    "        # Load the images if they are file paths, otherwise assume they are arrays\n",
    "        if isinstance(img1, str):\n",
    "            img1 = cv2.imread(img1)\n",
    "        if isinstance(img2, str):\n",
    "            img2 = cv2.imread(img2)\n",
    "        \n",
    "        # Ensure both images are in the same color space (BGR)\n",
    "        if len(img1.shape) < 3:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) < 3:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Draw markers on each image\n",
    "        if coord1:\n",
    "            cv2.circle(img1, (int(coord1[0]), int(coord1[1])), radius=10, color=(0, 165, 255), thickness=-1)\n",
    "        if coord2:\n",
    "            cv2.circle(img1, (int(coord2[0]), int(coord2[1])), radius=10, color=(0, 165, 255), thickness=-1)\n",
    "        # Keep previous marker positions on each subsequent image\n",
    "        for prev_coord1 in coords1[:idx]:\n",
    "            cv2.drawMarker(img1, (int(prev_coord1[0]), int(prev_coord1[1])), color=(0, 255, 0), \n",
    "                   markerType=cv2.MARKER_CROSS, thickness=2, markerSize=15)\n",
    "        for prev_coord2 in coords2[:idx]:\n",
    "            cv2.drawMarker(img2, (int(prev_coord2[0]), int(prev_coord2[1])), color=(0, 255, 0), \n",
    "                   markerType=cv2.MARKER_TILTED_CROSS, thickness=2, markerSize=15)\n",
    "        # Make both images the same height for horizontal concatenation\n",
    "        height = max(img1.shape[0], img2.shape[0])\n",
    "        img1 = cv2.resize(img1, (int(img1.shape[1] * height / img1.shape[0]), height))\n",
    "        img2 = cv2.resize(img2, (int(img2.shape[1] * height / img2.shape[0]), height))\n",
    "        \n",
    "        # Concatenate images horizontally\n",
    "        combined_image = cv2.hconcat([img1, img2])\n",
    "        \n",
    "        # Scale the combined image to have a fixed height\n",
    "        scale_ratio = fixed_height / combined_image.shape[0]\n",
    "        scaled_width = int(combined_image.shape[1] * scale_ratio)\n",
    "        resized_image = cv2.resize(combined_image, (scaled_width, fixed_height))\n",
    "        \n",
    "        # Set the window size to the resized image dimensions\n",
    "        cv2.resizeWindow(window_name, resized_image.shape[1], resized_image.shape[0])\n",
    "        \n",
    "        # Display the resized concatenated image in the window\n",
    "       \n",
    "        # Calculate the position to center the window\n",
    "        window_x = 1400\n",
    "        window_y = 50\n",
    "        \n",
    "        # Move the window to the center of the screen\n",
    "        cv2.moveWindow(window_name, window_x, window_y)\n",
    "        \n",
    "        cv2.imshow(window_name, resized_image)\n",
    "        \n",
    "        # Wait for the specified delay or until a key is pressed\n",
    "        if idx == len(images1) - 1:\n",
    "            # Keep the last image displayed until the user closes the window\n",
    "            print(\"Final image displayed. Close the window to end.\")\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(int(delay * 1000))  # Convert delay to milliseconds\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def display_images_with_graph(images1, coords1, images2, coords2, graph_data, fps=2, fixed_height=600, save_video=False, output_path=\"output_video.mp4\"):\n",
    "    \"\"\"\n",
    "    Display two sets of images side by side with a live-updating graph below them, \n",
    "    and optionally save the sequence as a video.\n",
    "\n",
    "    Parameters:\n",
    "        images1 (list): First set of images (file paths or image arrays).\n",
    "        coords1 (list): Coordinates for the first set of images (list of (x, y) tuples).\n",
    "        images2 (list): Second set of images (file paths or image arrays).\n",
    "        coords2 (list): Coordinates for the second set of images (list of (x, y) tuples).\n",
    "        graph_data (list): List of (x, y) tuples for graph plotting.\n",
    "        fps (int): Frames per second for image display.\n",
    "        fixed_height (int): Fixed height of the final display window.\n",
    "        save_video (bool): Whether to save the sequence as a video.\n",
    "        output_path (str): Path to save the video (if enabled).\n",
    "    \"\"\"\n",
    "    if len(images1) != len(coords1) or len(images2) != len(coords2) or len(images1) != len(graph_data):\n",
    "        raise ValueError(\"The number of images, coordinates, and graph data points must match.\")\n",
    "    \n",
    "    delay = 1 / fps  # Delay in seconds between frames\n",
    "    \n",
    "    # Create a resizable window\n",
    "    window_name = \"Image Viewer\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    for idx, (img1, coord1, img2, coord2, (x_vals, y_vals)) in enumerate(zip(images1, coords1, images2, coords2, graph_data)):\n",
    "        # Load the images if they are file paths, otherwise assume they are arrays\n",
    "        if isinstance(img1, str):\n",
    "            img1 = cv2.imread(img1)\n",
    "        if isinstance(img2, str):\n",
    "            img2 = cv2.imread(img2)\n",
    "        \n",
    "        # Ensure both images are in the same color space (BGR)\n",
    "        if len(img1.shape) < 3:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) < 3:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Draw markers on each image\n",
    "        if coord1:\n",
    "            cv2.drawMarker(img1, (int(coord1[0]), int(coord1[1])), color=(0, 0, 255), \n",
    "                           markerType=cv2.MARKER_CROSS, thickness=3, markerSize=50)\n",
    "        if coord2:\n",
    "            cv2.drawMarker(img2, (int(coord2[0]), int(coord2[1])), color=(0, 0, 255), \n",
    "                           markerType=cv2.MARKER_TILTED_CROSS, thickness=3, markerSize=50)\n",
    "        # Keep previous marker positions on each subsequent image\n",
    "        for prev_coord1 in coords1[:idx]:\n",
    "            cv2.drawMarker(img1, (int(prev_coord1[0]), int(prev_coord1[1])), color=(255, 0, 0), \n",
    "                   markerType=cv2.MARKER_CROSS, thickness=2, markerSize=40)\n",
    "        for prev_coord2 in coords2[:idx]:\n",
    "            cv2.drawMarker(img2, (int(prev_coord2[0]), int(prev_coord2[1])), color=(255, 0, 0), \n",
    "                   markerType=cv2.MARKER_TILTED_CROSS, thickness=2, markerSize=40)\n",
    "            \n",
    "        # Resize images to the fixed height\n",
    "        height = fixed_height\n",
    "        img1 = cv2.resize(img1, (int(img1.shape[1] * height / img1.shape[0]), height))\n",
    "        img2 = cv2.resize(img2, (int(img2.shape[1] * height / img2.shape[0]), height))\n",
    "        \n",
    "        # Concatenate images horizontally\n",
    "        combined_image = cv2.hconcat([img1, img2])\n",
    "        \n",
    "        # Create the graph as an image\n",
    "        fig, ax = plt.subplots(figsize=(4, 3))\n",
    "        max_x = max(graph_data, key=lambda x: x[0])[0]\n",
    "        max_y = max(graph_data, key=lambda x: x[1])[1]\n",
    "        ax.set_xlim([0, max_x * 1.1])\n",
    "        ax.set_ylim([0, max_y * 1.1])\n",
    "        ax.plot(x_vals, y_vals, marker=\"o\", color=\"blue\", linewidth=2)\n",
    "        # for prev_xy in graph_data[:idx]:\n",
    "        for prev_x_vals, prev_y_vals in graph_data[:idx]:\n",
    "            ax.plot(prev_x_vals, prev_y_vals,  marker=\"o\", color=\"black\", linewidth=2)\n",
    "        ax.set_xlabel(\"t(sec)\")\n",
    "        ax.set_ylabel(\"F(mN)\")\n",
    "        ax.grid(True)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.draw()\n",
    "        graph_img = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "        graph_img = graph_img.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Resize the graph to match the combined image width\n",
    "        graph_height = int(combined_image.shape[0] * 0.5)  # Scale graph height relative to images\n",
    "        graph_img = cv2.resize(graph_img, (combined_image.shape[1], graph_height))\n",
    "        \n",
    "        # Concatenate graph below the images\n",
    "        final_frame = cv2.vconcat([combined_image, graph_img])\n",
    "        \n",
    "        if video_writer is None and save_video:\n",
    "            frame_height, frame_width = final_frame.shape[:2]\n",
    "            video_writer = cv2.VideoWriter(\n",
    "                output_path,\n",
    "                cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "                fps,\n",
    "                (frame_width, frame_height),\n",
    "                )\n",
    "\n",
    "        # Resize window to match final frame dimensions\n",
    "        cv2.resizeWindow(window_name, final_frame.shape[1], final_frame.shape[0])\n",
    "        \n",
    "        # Calculate the position to center the window\n",
    "        window_x = 100\n",
    "        window_y = 50\n",
    "        \n",
    "        # Move the window to the center of the screen\n",
    "        cv2.moveWindow(window_name, window_x, window_y)\n",
    "        \n",
    "        # Display the final frame\n",
    "        cv2.imshow(window_name, final_frame)\n",
    "        \n",
    "        # Write to video if saving\n",
    "        if save_video and video_writer:\n",
    "            video_writer.write(cv2.cvtColor(final_frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Wait for the specified delay or until a key is pressed\n",
    "        if idx == len(images1) - 1:\n",
    "            # Keep the last frame displayed until the user closes the window\n",
    "            print(\"Final frame displayed. Close the window to end.\")\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(int(delay * 1000))  # Convert delay to milliseconds\n",
    "    \n",
    "    # Release the video writer\n",
    "    if save_video and video_writer:\n",
    "        video_writer.release()\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def display_images_with_graph2(\n",
    "    images1, coords1, images2, coords2, graph_data, fps=2, fixed_height=600, save_video=False, output_path=\"output_video.mp4\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Display two sets of images side by side with a live-updating graph below them,\n",
    "    and optionally save the sequence as a video.\n",
    "\n",
    "    Parameters:\n",
    "        images1 (list): First set of images (file paths or image arrays).\n",
    "        coords1 (list): Coordinates for the first set of images (list of (x, y) tuples).\n",
    "        images2 (list): Second set of images (file paths or image arrays).\n",
    "        coords2 (list): Coordinates for the second set of images (list of (x, y) tuples).\n",
    "        graph_data (list): List of (x, y) tuples for graph plotting.\n",
    "        fps (int): Frames per second for image display.\n",
    "        fixed_height (int): Fixed height of the final display window.\n",
    "        save_video (bool): Whether to save the sequence as a video.\n",
    "        output_path (str): Path to save the video (if enabled).\n",
    "    \"\"\"\n",
    "    if len(images1) != len(coords1) or len(images2) != len(coords2) or len(images1) != len(graph_data):\n",
    "        raise ValueError(\"The number of images, coordinates, and graph data points must match.\")\n",
    "\n",
    "    delay = 1 / fps  # Delay in seconds between frames\n",
    "\n",
    "    # Create a resizable window\n",
    "    window_name = \"Image Viewer\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Initialize video writer if saving the video\n",
    "    video_writer = None\n",
    "    frame_width = 2 * fixed_height  # Width proportional to height\n",
    "    frame_height = int(fixed_height + 200)  # Extra height for graph\n",
    "    if save_video:\n",
    "        video_writer = cv2.VideoWriter(\n",
    "            output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "            fps,\n",
    "            (frame_width, frame_height),\n",
    "        )\n",
    "\n",
    "    for idx, (img1, coord1, img2, coord2, (x_vals, y_vals)) in enumerate(zip(images1, coords1, images2, coords2, graph_data)):\n",
    "        # Load the images if they are file paths, otherwise assume they are arrays\n",
    "        if isinstance(img1, str):\n",
    "            img1 = cv2.imread(img1)\n",
    "        if isinstance(img2, str):\n",
    "            img2 = cv2.imread(img2)\n",
    "\n",
    "        # Ensure both images are in the same color space (BGR)\n",
    "        if len(img1.shape) < 3:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) < 3:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Draw markers on each image\n",
    "        if coord1:\n",
    "            cv2.circle(img1, (int(coord1[0]), int(coord1[1])), radius=15, color=(0, 165, 255), thickness=-1)\n",
    "        if coord2:\n",
    "            cv2.circle(img2, (int(coord2[0]), int(coord2[1])), radius=15, color=(0, 165, 255), thickness=-1)\n",
    "        # Keep previous marker positions on each subsequent image\n",
    "        for prev_coord1 in coords1[:idx]:\n",
    "            cv2.circle(img1, (int(prev_coord1[0]), int(prev_coord1[1])), radius=12, color=(255, 0, 0), thickness=-1)\n",
    "        for prev_coord2 in coords2[:idx]:\n",
    "            cv2.circle(img2, (int(prev_coord2[0]), int(prev_coord2[1])), radius=12, color=(255, 0, 0), thickness=-1)\n",
    "            \n",
    "        # Resize images to the fixed height\n",
    "        height = fixed_height\n",
    "        img1 = cv2.resize(img1, (int(img1.shape[1] * height / img1.shape[0]), height))\n",
    "        img2 = cv2.resize(img2, (int(img2.shape[1] * height / img2.shape[0]), height))\n",
    "\n",
    "        # Concatenate images horizontally\n",
    "        combined_image = cv2.hconcat([img1, img2])\n",
    "        # Create the graph as an image\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))  # Adjust width and height for a better aspect ratio\n",
    "        plt.subplots_adjust(left=0.2, right=0.9, top=0.9, bottom=0.2)  # Adjust margins\n",
    "        ax.plot(x_vals, y_vals, marker=\"o\", color='orange', linewidth=1.5)\n",
    "        for prev_x_vals, prev_y_vals in graph_data[:idx]:\n",
    "            ax.plot(prev_x_vals, prev_y_vals, marker=\"o\", color='blue', linewidth=1.5)\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Force (mN)\", labelpad=15, fontsize=12)\n",
    "        max_x = max(graph_data, key=lambda x: x[0])[0]\n",
    "        max_y = max(graph_data, key=lambda x: x[1])[1]\n",
    "        ax.set_xlim([0, max_x * 1.1])\n",
    "        ax.set_ylim([0, max_y * 1.1])\n",
    "        ax.grid(True)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.draw()\n",
    "        graph_img = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n",
    "        graph_img = graph_img.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Resize the graph while retaining proportions\n",
    "        graph_height, graph_width = graph_img.shape[:2]\n",
    "        scale_ratio = combined_image.shape[1] / graph_width\n",
    "        new_graph_width = int(graph_width * scale_ratio)\n",
    "        new_graph_height = int(graph_height * scale_ratio)\n",
    "        graph_img = cv2.resize(graph_img, (new_graph_width, new_graph_height))\n",
    "\n",
    "        # Resize the graph to match the width of the combined image\n",
    "        # graph_img = cv2.resize(graph_img, (combined_image.shape[1], 200))\n",
    "        # Convert graph image to RGB\n",
    "        graph_img = cv2.cvtColor(graph_img, cv2.COLOR_BGR2RGB)\n",
    "        # Concatenate graph below the images\n",
    "        final_frame = cv2.vconcat([combined_image, graph_img])\n",
    "        \n",
    "        # Resize the graph while retaining proportions\n",
    "        # graph_height, graph_width = graph_img.shape[:2]\n",
    "        # scale_ratio = combined_image.shape[1] / graph_width\n",
    "        # new_graph_width = int(graph_width * scale_ratio)\n",
    "        # new_graph_height = int(graph_height * scale_ratio)\n",
    "        # graph_img = cv2.resize(graph_img, (new_graph_width, new_graph_height))\n",
    "\n",
    "        # Concatenate graph below the images\n",
    "        final_frame = cv2.vconcat([combined_image, graph_img])\n",
    "\n",
    "        # Resize window to match final frame dimensions\n",
    "        cv2.resizeWindow(window_name, final_frame.shape[1], final_frame.shape[0])\n",
    "\n",
    "        # Display the final frame\n",
    "        cv2.imshow(window_name, final_frame)\n",
    "\n",
    "        # Initialize video writer if not already initialized\n",
    "        if save_video and video_writer is None:\n",
    "            frame_width, frame_height = final_frame.shape[1], final_frame.shape[0]\n",
    "            video_writer = cv2.VideoWriter(\n",
    "                output_path,\n",
    "                cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "                fps,\n",
    "                (frame_width, frame_height),\n",
    "            )\n",
    "\n",
    "        # Now write the frame\n",
    "        if save_video:\n",
    "            video_writer.write(final_frame)\n",
    "\n",
    "\n",
    "        if idx == len(images1) - 1:\n",
    "            print(\"Final frame displayed. Close the window to end.\")\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(int(delay * 1000))\n",
    "\n",
    "    if save_video and video_writer:\n",
    "        video_writer.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    #####################\n",
    "    # Save the last frame of the video separately\n",
    "    # last_frame_path = os.path.join(save_folder, \"last_frame_video.jpg\")\n",
    "    # cv2.imwrite(last_frame_path, resized_frame_for_video)\n",
    "\n",
    "    # # Save the last frame as shown in the cv2 window separately\n",
    "    # last_frame_window_path = os.path.join(save_folder, \"last_frame_window.jpg\")\n",
    "    # cv2.imwrite(last_frame_window_path, final_frame)\n",
    "\n",
    "    # # Combine the two images side by side\n",
    "    # last_frame_video = cv2.imread(last_frame_path)\n",
    "    # last_frame_window = cv2.imread(last_frame_window_path)\n",
    "\n",
    "    # # Ensure both images have the same height for concatenation\n",
    "    # height = max(last_frame_video.shape[0], last_frame_window.shape[0])\n",
    "    # last_frame_video = cv2.resize(last_frame_video, (int(last_frame_video.shape[1] * height / last_frame_video.shape[0]), height))\n",
    "    # last_frame_window = cv2.resize(last_frame_window, (int(last_frame_window.shape[1] * height / last_frame_window.shape[0]), height))\n",
    "\n",
    "    # # Concatenate the images horizontally\n",
    "    # combined_last_frames = cv2.hconcat([last_frame_video, last_frame_window])\n",
    "\n",
    "    # # Save the combined image\n",
    "    # combined_last_frames_path = os.path.join(save_folder, \"combined_last_frames.jpg\")\n",
    "    # cv2.imwrite(combined_last_frames_path, combined_last_frames)\n",
    "\n",
    "    # print(f\"Last frame of video saved at: {last_frame_path}\")\n",
    "    # print(f\"Last frame from window saved at: {last_frame_window_path}\")\n",
    "    # print(f\"Combined last frames saved at: {combined_last_frames_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def display_images_with_graph3(\n",
    "    images1, coords1, images2, coords2, graph_data, fps=2, fixed_height=600, save_video=False, output_path=\"output_video.mp4\"\n",
    "):\n",
    "    if len(images1) != len(coords1) or len(images2) != len(coords2) or len(images1) != len(graph_data):\n",
    "        raise ValueError(\"The number of images, coordinates, and graph data points must match.\")\n",
    "\n",
    "    delay = 1 / fps\n",
    "    window_name = \"Image Viewer\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    video_writer = None  # Will be initialized after first frame\n",
    "\n",
    "    for idx, (img1, coord1, img2, coord2, (x_vals, y_vals)) in enumerate(zip(images1, coords1, images2, coords2, graph_data)):\n",
    "        # Load images if they are file paths\n",
    "        img1 = cv2.imread(img1) if isinstance(img1, str) else img1\n",
    "        img2 = cv2.imread(img2) if isinstance(img2, str) else img2\n",
    "\n",
    "        # Convert grayscale to BGR\n",
    "        if len(img1.shape) < 3:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) < 3:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Draw current and past markers\n",
    "        if coord1:\n",
    "            cv2.circle(img1, (int(coord1[0]), int(coord1[1])), radius=15, color=(0, 165, 255), thickness=-1)\n",
    "        if coord2:\n",
    "            cv2.circle(img2, (int(coord2[0]), int(coord2[1])), radius=15, color=(0, 165, 255), thickness=-1)\n",
    "        for prev_coord1 in coords1[:idx]:\n",
    "            cv2.circle(img1, (int(prev_coord1[0]), int(prev_coord1[1])), radius=12, color=(255, 0, 0), thickness=-1)\n",
    "        for prev_coord2 in coords2[:idx]:\n",
    "            cv2.circle(img2, (int(prev_coord2[0]), int(prev_coord2[1])), radius=12, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "        # Resize images to fixed height\n",
    "        img1 = cv2.resize(img1, (int(img1.shape[1] * fixed_height / img1.shape[0]), fixed_height))\n",
    "        img2 = cv2.resize(img2, (int(img2.shape[1] * fixed_height / img2.shape[0]), fixed_height))\n",
    "\n",
    "        # Combine images horizontally\n",
    "        combined_image = cv2.hconcat([img1, img2])\n",
    "\n",
    "        # Create graph using matplotlib\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        plt.subplots_adjust(left=0.2, right=0.9, top=0.9, bottom=0.2)\n",
    "        ax.plot(x_vals, y_vals, marker=\"o\", color='orange', linewidth=1.5)\n",
    "        for prev_x_vals, prev_y_vals in graph_data[:idx]:\n",
    "            ax.plot(prev_x_vals, prev_y_vals, marker=\"o\", color='blue', linewidth=1.5)\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Force (mN)\", labelpad=15, fontsize=12)\n",
    "        max_x = max(graph_data, key=lambda x: x[0])[0]\n",
    "        max_y = max(graph_data, key=lambda x: x[1])[1]\n",
    "        ax.set_xlim([0, max_x * 1.1])\n",
    "        ax.set_ylim([0, max_y * 1.1])\n",
    "        ax.grid(True)\n",
    "\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.draw()\n",
    "        graph_img = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n",
    "        graph_img = graph_img.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Resize graph to match image width\n",
    "        scale_ratio = combined_image.shape[1] / graph_img.shape[1]\n",
    "        graph_img = cv2.resize(graph_img, (combined_image.shape[1], int(graph_img.shape[0] * scale_ratio)))\n",
    "\n",
    "        # Convert graph image to BGR for OpenCV\n",
    "        graph_img = cv2.cvtColor(graph_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Combine image and graph vertically\n",
    "        final_frame = cv2.vconcat([combined_image, graph_img])\n",
    "\n",
    "        # Display\n",
    "        cv2.resizeWindow(window_name, final_frame.shape[1], final_frame.shape[0])\n",
    "        cv2.imshow(window_name, final_frame)\n",
    "\n",
    "        # Initialize writer on first frame (ensures correct resolution)\n",
    "        if save_video and video_writer is None:\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            frame_height, frame_width = final_frame.shape[:2]\n",
    "            video_writer = cv2.VideoWriter(\n",
    "                output_path,\n",
    "                cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "                fps,\n",
    "                (frame_width, frame_height),\n",
    "            )\n",
    "\n",
    "        # Write to video\n",
    "        if save_video:\n",
    "            video_writer.write(final_frame)\n",
    "\n",
    "        # Wait for next frame\n",
    "        if idx == len(images1) - 1:\n",
    "            print(\"Final frame displayed. Close the window to end.\")\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(int(delay * 1000))\n",
    "\n",
    "    if save_video and video_writer:\n",
    "        video_writer.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def parallel_video2(\n",
    "    images, fps=2, fixed_height=600, save_video=False, output_path=\"output_video.mp4\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Display and optionally save a video of multiple synchronized views.\n",
    "\n",
    "    Parameters:\n",
    "        images (list of lists): List of N lists of image paths/arrays for N views.\n",
    "        fps (int): Frames per second.\n",
    "        fixed_height (int): Height for each image.\n",
    "        save_video (bool): Whether to save the video.\n",
    "        output_path (str): Path to save the output video.\n",
    "    \"\"\"\n",
    "\n",
    "    delay = 1 / fps\n",
    "    window_name = \"Image Viewer\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    num_views = len(images)\n",
    "    num_frames = len(images[0])\n",
    "    \n",
    "    # Ensure all views have the same number of frames\n",
    "    if not all(len(view) == num_frames for view in images):\n",
    "        raise ValueError(\"All views must have the same number of frames.\")\n",
    "\n",
    "    # Determine layout\n",
    "    if num_views <= 3:\n",
    "        layout = \"horizontal\"\n",
    "    else:\n",
    "        layout = \"grid\"\n",
    "        grid_cols = m.ceil(m.sqrt(num_views))\n",
    "        grid_rows = m.ceil(num_views / grid_cols)\n",
    "\n",
    "    video_writer = None\n",
    "\n",
    "    for idx in range(num_frames):\n",
    "        resized_images = []\n",
    "\n",
    "        # Process each view\n",
    "        for view in images:\n",
    "            img = view[idx]\n",
    "            if isinstance(img, str):\n",
    "                img = cv2.imread(img)\n",
    "            if len(img.shape) < 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            img = cv2.resize(img, (int(img.shape[1] * fixed_height / img.shape[0]), fixed_height))\n",
    "            resized_images.append(img)\n",
    "\n",
    "        # Combine images\n",
    "        if layout == \"horizontal\":\n",
    "            combined_image = cv2.hconcat(resized_images)\n",
    "        else:\n",
    "            # Pad the images list to fill the grid\n",
    "            while len(resized_images) < grid_rows * grid_cols:\n",
    "                height, width = resized_images[0].shape[:2]\n",
    "                resized_images.append(np.zeros((height, width, 3), dtype=np.uint8))\n",
    "            \n",
    "            rows = []\n",
    "            for r in range(grid_rows):\n",
    "                row_imgs = resized_images[r * grid_cols:(r + 1) * grid_cols]\n",
    "                row = cv2.hconcat(row_imgs)\n",
    "                rows.append(row)\n",
    "            combined_image = cv2.vconcat(rows)\n",
    "\n",
    "        # Resize window and show image\n",
    "        cv2.resizeWindow(window_name, combined_image.shape[1], combined_image.shape[0])\n",
    "        cv2.imshow(window_name, combined_image)\n",
    "\n",
    "        # Initialize video writer if needed\n",
    "        if save_video and video_writer is None:\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            frame_height, frame_width = combined_image.shape[:2]\n",
    "            video_writer = cv2.VideoWriter(\n",
    "                output_path,\n",
    "                cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "                fps,\n",
    "                (frame_width, frame_height),\n",
    "            )\n",
    "\n",
    "        # Save video\n",
    "        if save_video:\n",
    "            video_writer.write(combined_image)\n",
    "\n",
    "        # Wait\n",
    "        if idx == num_frames - 1:\n",
    "            print(\"Final frame displayed. Close the window to end.\")\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(int(delay * 1000))\n",
    "\n",
    "    if save_video and video_writer:\n",
    "        video_writer.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 5\n",
      "10 175\n",
      "50\n",
      "['436.0', ' 2121.0', ' 68.0', ' 83.0', ' C:\\\\Users\\\\Amir\\\\Documents\\\\PHD\\\\Experiments\\\\Force Measurements\\\\Exp2.0_Methods-paper\\\\79_2_side\\\\cropped\\\\5775_CROPED.JPG', ' path time not found', ' 0', ' Auto\\n']\n",
      "50\n",
      "['1687.0', ' 1212.0', ' 406.0', ' 394.0', ' C:\\\\Users\\\\Amir\\\\Documents\\\\PHD\\\\Experiments\\\\Force Measurements\\\\Exp2.0_Methods-paper\\\\79_2_top\\\\cropped\\\\1067_CROPED.JPG', ' path time not found', ' 0', ' Auto\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_29160\\1515899450.py:452: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  graph_img = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final frame displayed. Close the window to end.\n"
     ]
    }
   ],
   "source": [
    "#%%  Define the experiment and event numbers\n",
    "# exp_num = 30\n",
    "# event_num = 1\n",
    "# find the event corresponding to exp_num and event_num:\n",
    "i = 70 # 40 (simple) , 20,120 (bump from dist2tip), i=70->event 79_2\n",
    "event = events[i]\n",
    "# event.frm0_top = 10 # original\n",
    "\n",
    "print(event.p.exp_num,event.event_num)\n",
    "print(event.frm0_top,event.frm_dec_top)\n",
    "\n",
    "# start video from initial contact frame for both views\n",
    "\n",
    "# Define paths to the video frames\n",
    "side_view_path = r\"C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Data\\sample trajectory\\79_2_side\\cropped\"\n",
    "top_view_path = r\"C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Data\\sample trajectory\\79_2_top\\cropped\"\n",
    "vid_path = r\"C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Data\\sample trajectory\"\n",
    "\n",
    "top_view_files = [os.path.join(top_view_path, f) for f in os.listdir(top_view_path) if os.path.isfile(os.path.join(top_view_path, f))]\n",
    "side_view_files = [os.path.join(side_view_path, f) for f in os.listdir(side_view_path) if os.path.isfile(os.path.join(side_view_path, f))]                                                                    \n",
    "\n",
    "# Define the number of frames\n",
    "fr = 70\n",
    "fr = min(fr,len(top_view_files))\n",
    "\n",
    "top_images = top_view_files[event.frm0_top:event.frm_dec_top][:fr]\n",
    "side_images = side_view_files[event.frm0_side:event.frm_dec_side][:fr]\n",
    "\n",
    "#################\n",
    "# Load coordinates from another track file in the folder\n",
    "track_side_folder_path = r'C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Data\\sample trajectory\\79_2_side\\CSRT_079_2\\Rois_cropped_'\n",
    "track_top_folder_path = r'C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Data\\sample trajectory\\79_2_top\\CSRT_079_2\\Rois_cropped_'\n",
    "\n",
    "# List all files in the side and top track folders\n",
    "track_side_path = os.path.join(track_side_folder_path, 'CSRT_079_side_2.txt')\n",
    "track_top_path = os.path.join(track_top_folder_path, 'CSRT_079_top_2.txt')\n",
    "\n",
    "# Read the tracked coordinates from the side file \n",
    "# xz_track_side = uf.funcget_tracked_data(track_side_path,[0,-1],'top','nikon')\n",
    "# read the tracked coordinates\n",
    "xz_track_side = uf.funcget_tracked_data(track_side_path, [0, -1], 'side','pi')\n",
    "xy_track_top = uf.funcget_tracked_data(track_top_path, [0, -1], 'top','pi')\n",
    "\n",
    "#################\n",
    "\n",
    "# top tracked coordiantes\n",
    "x_coor_top = xy_track_top[0][event.frm0_top:event.frm_dec_top][:fr]\n",
    "y_coor_top = xy_track_top[1][event.frm0_top:event.frm_dec_top][:fr]\n",
    "# side tracked coordiantes\n",
    "x_coor_side = xz_track_side[0][event.frm0_side:event.frm_dec_side][:fr]\n",
    "z_coor_side = xz_track_side[1][event.frm0_side:event.frm_dec_side][:fr]\n",
    "\n",
    "side_xz_coor = list(zip(x_coor_side,z_coor_side))\n",
    "top_xy_coor = list(zip(x_coor_top,y_coor_top))\n",
    "\n",
    "t = event.timer[event.frm0_top:event.frm_dec_top][:fr]-event.timer[event.frm0_top]\n",
    "# force data\n",
    "force_data = list(zip(t,event.F_bean[event.frm0_top:event.frm_dec_top][:fr]))\n",
    "\n",
    "# parallel_video(top_images, top_xy_coor,side_images, side_xz_coor, fps=2)\n",
    "display_images_with_graph3(top_images, top_xy_coor,side_images, side_xz_coor, graph_data=force_data , fps=10,\n",
    "                          fixed_height=500, save_video=True, output_path=vid_path+\"\\\\side_top_crop_f(t)_video.mp4\")\n",
    "\n",
    "\n",
    "#################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top images: 10\n",
      "Number of side images: 10\n",
      "Number of top x and y coordinates: 10, 10\n",
      "Number of side x and z coordinates: 10, 10\n",
      "Length of xz_track_side: 82, 82\n",
      "Length of xy_track_top: 82, 82\n",
      "Event frame range for top: 10 to 175\n",
      "Event frame range for side: 6 to 171\n",
      "Length of sliced x_coor_top: 10\n",
      "Length of sliced y_coor_top: 10\n",
      "Length of sliced x_coor_side: 10\n",
      "Length of sliced z_coor_side: 10\n",
      "fr=10\n",
      "Box centers from the file:\n",
      "\n",
      "Box centers from funcget_tracked_data:\n",
      "\n",
      "Comparison of box centers:\n",
      "Box 1: File center = (1688.0, 1618.0), Funcget_tracked_data center = (1688.0, 1618.0)\n",
      "Box 2: File center = (1688.0, 1618.0), Funcget_tracked_data center = (1688.0, 1618.0)\n",
      "Box 3: File center = (1689.0, 1620.0), Funcget_tracked_data center = (1689.0, 1620.0)\n",
      "Box 4: File center = (1695.5, 1619.0), Funcget_tracked_data center = (1695.5, 1619.0)\n",
      "Box 5: File center = (1701.0, 1615.5), Funcget_tracked_data center = (1701.0, 1615.5)\n",
      "Box 6: File center = (1706.0, 1615.5), Funcget_tracked_data center = (1706.0, 1615.5)\n",
      "Box 7: File center = (1710.5, 1615.0), Funcget_tracked_data center = (1710.5, 1615.0)\n",
      "Box 8: File center = (1721.0, 1610.5), Funcget_tracked_data center = (1721.0, 1610.5)\n",
      "Box 9: File center = (1725.5, 1606.0), Funcget_tracked_data center = (1725.5, 1606.0)\n",
      "Box 10: File center = (1727.5, 1604.0), Funcget_tracked_data center = (1727.5, 1604.0)\n"
     ]
    }
   ],
   "source": [
    "# checks\n",
    "dec_x_track_top = event.x_track_top_pix[event.frm0_top:event.frm_dec_top][:fr]\n",
    "dec_y_track_top = event.y_track_top_pix[event.frm0_top:event.frm_dec_top][:fr]\n",
    "top_xy_coor = list(zip(dec_x_track_top,dec_y_track_top))\n",
    "\n",
    "# side images and tracked coordiantes\n",
    "side_images = side_view_files[event.frm0_side:event.frm_dec_side][:fr]\n",
    "dec_x_track_side = event.x_track_side0[event.frm0_side:event.frm_dec_side][:fr]\n",
    "dec_y_track_side = event.z_track_side0[event.frm0_side:event.frm_dec_side][:fr]\n",
    "side_xz_coor = list(zip(dec_x_track_side,dec_y_track_side))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Number of top images: {len(top_images)}\")\n",
    "print(f\"Number of side images: {len(side_images)}\")\n",
    "print(f\"Number of top x and y coordinates: {len(x_coor_top)}, {len(y_coor_top)}\")\n",
    "print(f\"Number of side x and z coordinates: {len(x_coor_side)}, {len(z_coor_side)}\")\n",
    "# Check the length of the coordinates extracted from funcget_tracked_data\n",
    "print(f\"Length of xz_track_side: {len(xz_track_side[0])}, {len(xz_track_side[1])}\")\n",
    "print(f\"Length of xy_track_top: {len(xy_track_top[0])}, {len(xy_track_top[1])}\")\n",
    "\n",
    "# Ensure slicing is done correctly\n",
    "print(f\"Event frame range for top: {event.frm0_top} to {event.frm_dec_top}\")\n",
    "print(f\"Event frame range for side: {event.frm0_side} to {event.frm_dec_side}\")\n",
    "\n",
    "# Check the slicing operation\n",
    "print(f\"Length of sliced x_coor_top: {len(x_coor_top)}\")\n",
    "print(f\"Length of sliced y_coor_top: {len(y_coor_top)}\")\n",
    "print(f\"Length of sliced x_coor_side: {len(x_coor_side)}\")\n",
    "print(f\"Length of sliced z_coor_side: {len(z_coor_side)}\")\n",
    "print(f\"{fr=}\")\n",
    "\n",
    "# Print the first lines in the track top file\n",
    "# Show 10 box centers from the file\n",
    "print(\"Box centers from the file:\")\n",
    "box_centers_file = []\n",
    "with open(track_top_path, 'r') as file:\n",
    "    for i in range(10):  # Extract the first 10 box centers\n",
    "        line = file.readline().strip()\n",
    "        values = line.split(',')[:4]  # Extract only the first 4 values\n",
    "        x_left, y_top, width, height = map(float, values)\n",
    "        x_center = x_left + width / 2\n",
    "        y_center = y_top + height / 2\n",
    "        box_centers_file.append((x_center, y_center))\n",
    "        # print(f\"Center of the box: ({x_center}, {y_center})\")\n",
    "\n",
    "# Compare to the box centers obtained from funcget_tracked_data\n",
    "print(\"\\nBox centers from funcget_tracked_data:\")\n",
    "box_centers_func = list(zip(xy_track_top[0][:10], xy_track_top[1][:10]))\n",
    "# for center in box_centers_func:\n",
    "    # print(f\"Center of the box: {center}\")\n",
    "\n",
    "# Compare the two lists\n",
    "print(\"\\nComparison of box centers:\")\n",
    "for i, (file_center, func_center) in enumerate(zip(box_centers_file, box_centers_func)):\n",
    "    print(f\"Box {i + 1}: File center = {file_center}, Funcget_tracked_data center = {func_center}\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top images: 75\n",
      "Final frame displayed. Close the window to end.\n"
     ]
    }
   ],
   "source": [
    "# Create a video from top-side-front images\n",
    "# Each list inside images corresponds to a different view (e.g., top, side, front)\n",
    "exp_num = 9\n",
    "exp_path = rf\"C:\\Users\\Amir\\Documents\\PHD\\Experiments\\Force Measurements\\Exp2h_tilt\\{exp_num}\"\n",
    "top_path = os.path.join(exp_path, \"top1_cropped\\Croped_1\")\n",
    "top_images = [os.path.join(top_path, f) for f in os.listdir(top_path) if f.endswith('.JPG')][0:750:10]\n",
    "side_path = os.path.join(exp_path, \"side1_cropped\\Croped_1\")\n",
    "side_images = [os.path.join(side_path, f) for f in os.listdir(side_path) if f.endswith('.JPG')][:750:10]\n",
    "front_path = os.path.join(exp_path, \"front1_cropped\\Croped_1\")\n",
    "front_images = [os.path.join(front_path, f) for f in os.listdir(front_path) if f.endswith('.JPG') ][:750:10]\n",
    "print(fr\"Number of top images: {len(top_images)}\")\n",
    "images = [top_images, side_images, front_images]\n",
    "# Create a video with the images\n",
    "output_path = os.path.join(exp_path, \"output\", \"parallel_video.mp4\")\n",
    "parallel_video2(images, fps=5, fixed_height=400, save_video=True, output_path=output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at: C:\\Users\\Amir\\Documents\\PHD\\Experiments\\Force Measurements\\Exp2h_tilt\\4\\side1_cropped\\output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# Create a video from images in a folder\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def create_video_from_images(image_folder, output_video_path, fps=30, frame_size=None,file_total=100, skip=1):\n",
    "    \"\"\"\n",
    "    Create a video from images in a folder.\n",
    "\n",
    "    Parameters:\n",
    "        image_folder (str): Path to the folder containing images.\n",
    "        output_video_path (str): Full path to save the output video (including .mp4).\n",
    "        fps (int): Frames per second for the video.\n",
    "        frame_size (tuple): Desired frame size (width, height). If None, uses first image size.\n",
    "    \"\"\"\n",
    "    # Get a sorted list of image file paths\n",
    "    image_files = sorted([\n",
    "        os.path.join(image_folder, f) \n",
    "        for f in os.listdir(image_folder) \n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])[:file_total:skip]\n",
    "\n",
    "    if not image_files:\n",
    "        raise ValueError(f\"No valid images found in folder: {image_folder}\")\n",
    "    \n",
    "    # Load the first image to determine size if needed\n",
    "    first_image = cv2.imread(image_files[0])\n",
    "    if first_image is None:\n",
    "        raise ValueError(f\"Failed to read the first image: {image_files[0]}\")\n",
    "\n",
    "    if frame_size is None:\n",
    "        frame_size = (first_image.shape[1], first_image.shape[0])  # width, height\n",
    "\n",
    "    # Initialize the video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, frame_size)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img = cv2.imread(image_file)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Unable to read image {image_file}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if (img.shape[1], img.shape[0]) != frame_size:\n",
    "            img = cv2.resize(img, frame_size)\n",
    "\n",
    "        video_writer.write(img)\n",
    "\n",
    "    video_writer.release()\n",
    "    print(f\"Video saved at: {output_video_path}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = r\"C:\\Users\\Amir\\Documents\\PHD\\Experiments\\Force Measurements\\Exp2h_tilt\\4\\side1_cropped\\Croped_1\"\n",
    "output_video_path = r\"C:\\Users\\Amir\\Documents\\PHD\\Experiments\\Force Measurements\\Exp2h_tilt\\4\\side1_cropped\\output_video.mp4\"\n",
    "create_video_from_images(image_folder, output_video_path, fps=5,file_total=500,skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
