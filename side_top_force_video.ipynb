{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create video with plot visualization of force trajectory over time.\n",
    "1. Video of top and side views with tracking of the pendulum rod tip.\n",
    "2. Contact point of the stem along the rod- in side view.\n",
    "3. visualization of force trajectory over time (with deflection, angle, and contact as well?).\n",
    "4. maybe add an arrow of the Fxy direction in the top view video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "c:\\Users\\Amir\\Documents\\PHD\\Python\\GitHub\\Amir_Repositories\\Repo_article0\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "# generic\n",
    "import sys\n",
    "import numpy as np\n",
    "import os,glob # for listing files in folder\n",
    "import re # regular expressions\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn\n",
    "import math as m\n",
    "import cv2\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial import distance as sci_distance\n",
    "from scipy.stats import kruskal\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.lines as mlines\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# custom\n",
    "import exp2funcs_clean # writch to updated exp2 functions\n",
    "# sys.path.append('..')\n",
    "import useful_functions as uf \n",
    "\n",
    "#general parameters\n",
    "cmap = plt.get_cmap('viridis')\n",
    "fs = 16 # standard font size for plots\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "importlib.reload(uf)\n",
    "importlib.reload(exp2funcs_clean)\n",
    "\n",
    "save_folder = r'C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Images'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "root_path = r'C:\\Users\\Amir\\Documents\\PHD\\Experiments\\Force Measurements'\n",
    "basepath = root_path+r'\\Exp2_Pendulum' # pendulum exp folder\n",
    "excel= r'\\Exp2_supplementary_measurements_events.csv'\n",
    "\n",
    "# straw exp data\n",
    "data_panda = pd.read_csv(basepath+excel)\n",
    "\n",
    "\n",
    "# import tracked data, initiate variables\n",
    "track_sup_path = r'\\track_logs'\n",
    "track_folder_path = basepath+track_sup_path\n",
    "\n",
    "track_contact_path = r'\\contact_track_logs'\n",
    "contact_folder_path = basepath+track_contact_path\n",
    "\n",
    "track_near_sup_path = r'\\twine_init_logs'\n",
    "track_near_sup_folder_path = basepath+track_near_sup_path\n",
    "\n",
    "h5_path = r'\\Measurements\\root_stem_results'\n",
    "h5_folder_path = basepath+h5_path\n",
    "\n",
    "E_path = r'\\Young_moduli'\n",
    "E_folder_path = basepath+E_path\n",
    "\n",
    "N_track = len(os.listdir(track_folder_path)) # get number of files in track folder\n",
    "N_contact=len(os.listdir(contact_folder_path)) # get number of files in contact folder\n",
    "N_tot = len(data_panda) # get number of lines in excel\n",
    "N_E = len(os.listdir(E_folder_path))\n",
    "\n",
    "\n",
    "#%% remove problematic events from raw data\n",
    "delete_rows = [] # save rows to delete\n",
    "problem_exp = [] # exp_num of problem events\n",
    "\n",
    "for i in range(N_tot): # remove problem events and non-Helda events\n",
    "    if data_panda.at[i,'problem']!='na' or data_panda.at[i,'Bean_Strain']!='Helda':\n",
    "        delete_rows.append(i)\n",
    "        problem_exp.append(data_panda.at[i,'Exp_num'])\n",
    "N = N_tot - len(delete_rows) # modify num of rows\n",
    "\n",
    "data_panda = data_panda.drop(data_panda.index[delete_rows]) # remove prob. events\n",
    "data_panda = data_panda.reset_index() # redo index\n",
    "#%% get misc. file lists\n",
    "\n",
    "# get track files for support bottom coordinates\n",
    "remove_chars = re.compile('[,_\\.!?]') # what to remove from strings\n",
    "track_dict = {} # save support track in dictionary by exp and events\n",
    "i=0 # start with first track file\n",
    "for file in glob.glob(os.path.join(track_folder_path, '*.txt')): # for each event:\n",
    "    exp = int(re.findall('_\\d{3,4}_',file)[0].replace('_','')) # find exp number (3-4 digits)\n",
    "    event = int(re.findall('[0-9]',re.findall('_\\d{1}\\D',file)[0].replace('_',''))[0]) # find event number\n",
    "    viewt = re.findall('(side{1}|top{1})',file)[0] #.replace('_','')\n",
    "    track_dict[(exp,event,viewt)] = [file] # add new exp\n",
    "    i+=1\n",
    "\n",
    "# get track files for stem-support contact coordinates\n",
    "contact_dict = {} # save support contact track in dictionary by exp and events\n",
    "i=0 # start with first contact file\n",
    "for file in glob.glob(os.path.join(contact_folder_path, '*.txt')): # for each event:\n",
    "    exp = int(re.findall('_\\d{3,4}_',file)[0].replace('_','')) # find exp number (3-4 digits)\n",
    "    event = int(re.findall('_[0-9]_',file)[0].replace('_','')) # find event number\n",
    "    contact_dict[(exp,event)] = [file] # add new exp\n",
    "    i+=1\n",
    "\n",
    "# get track files for 2 stem positions on either side of support\n",
    "near_sup_track_dict = {}\n",
    "i=0 # start with first stem_near_sup file\n",
    "for file in glob.glob(os.path.join(track_near_sup_folder_path, '*.txt')): # for each event:\n",
    "    exp = int(re.findall('_\\d{3,4}_',file)[0].replace('_','')) # find exp number (3-4 digits)\n",
    "    event = int(re.findall('_[0-9]_',file)[0].replace('_','')) # find event number\n",
    "    near_sup_track_dict[(exp,event)] = [file] # add new exp\n",
    "    i+=1\n",
    "\n",
    "# get h5 files for stem near support\n",
    "h5_dict = {}\n",
    "i=0 # start with first h5 file\n",
    "for file in glob.glob(os.path.join(h5_folder_path, '*.h5')): # for each event:\n",
    "    exp = int(re.findall('interekt_\\d{2,3}_',file)[0].split('_')[1]) # find exp number (3-4 digits)\n",
    "    event = int(re.findall('e_[0-9]_',file)[0].split('_')[1]) # find event number\n",
    "    start_frame = int(re.findall('_\\d{2,5}-\\d{2,5}',file)[0].replace('_','').split('-')[0]) # find start frame\n",
    "    h5_dict[(exp,event,start_frame)] = [file] # add new exp\n",
    "    i+=1\n",
    "\n",
    "# get Young modulus files\n",
    "E_dict = {}\n",
    "for file in glob.glob(os.path.join(E_folder_path, '*.csv')):\n",
    "    exp = int(re.findall('\\d{2,3}',file)[0])\n",
    "    E_dict[exp]=pd.read_csv(file,header=None)\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/264 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [00:11<00:00, 23.80it/s]\n"
     ]
    }
   ],
   "source": [
    "#%% clear plants and events\n",
    "plants = []\n",
    "events = []\n",
    "#%% populate plant and event instances\n",
    "i = 0\n",
    "N = len(data_panda)\n",
    "for i in tqdm(range(N)): # N\n",
    "    exp = int(re.findall('\\d{3,4}',data_panda.at[i,'Exp_num'])[0]) # exp num\n",
    "    view = data_panda.at[i,'View']  # side of top view\n",
    "    if view == 'top':\n",
    "        plants[-1].pix2cm_t = float(data_panda.at[i,'Top_pix2cm'])\n",
    "\n",
    "    if i==0 or exp!=plants[-1].exp_num: # append new plant with data from pandas\n",
    "        #basic data\n",
    "        plants.append(exp2funcs_clean.Plant(data_panda,basepath,i,exp))\n",
    "        # view dependent data\n",
    "        plants[-1].view_data(data_panda,i)\n",
    "        # circumnutation data\n",
    "        plants[-1].cn_data(data_panda,i)\n",
    "        #Youngs modulus by segment with avg\n",
    "        plants[-1].getE(E_dict)\n",
    "\n",
    "\n",
    "    event =  int(re.findall('_[0-9]',data_panda.at[i,\n",
    "       'Exp_num'])[0].replace('_','')) # get event number\n",
    "\n",
    "\n",
    "    # if this is the 1st event or the previous event_num is different from the current one:\n",
    "    # add new event to list\n",
    "    if len(events)==0 or events[-1].event_num != event or \\\n",
    "        events[-1].p.exp_num != exp:\n",
    "        events.append(exp2funcs_clean.Event(plants[-1],data_panda,i))\n",
    "    events[-1].event_num = event\n",
    "\n",
    "    # view dependent data\n",
    "    events[-1].view_data(data_panda,i,view)\n",
    "\n",
    "    # get automated extraction of twine(decision) time\n",
    "    events[-1].get_twine_time(exp,event,view,\n",
    "                      h5_dict,near_sup_track_dict,50,track_dict,to_plot=0)\n",
    "\n",
    "\n",
    "    # get track data, select decision period data, pix2cm,\n",
    "    events[-1].event_base_calcs(view,track_dict,contact_dict)\n",
    "    # calc\n",
    "    events[-1].event_calc_variables(view)\n",
    "    # print(f'i={i}, exp number {exp}, {event}') # print progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create video of side and top view in split screen for a specific event\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "\n",
    "def parallel_video(images1, coords1, images2, coords2, fps=2, fixed_height=300):\n",
    "    \"\"\"\n",
    "    Display two sets of images side by side with markers in a resizable window.\n",
    "    \n",
    "    Parameters:\n",
    "        images1 (list): First set of images (file paths or image arrays).\n",
    "        coords1 (list): Coordinates for the first set of images (list of (x, y) tuples).\n",
    "        images2 (list): Second set of images (file paths or image arrays).\n",
    "        coords2 (list): Coordinates for the second set of images (list of (x, y) tuples).\n",
    "        fps (int): Frames per second for image display.\n",
    "        fixed_height (int): Fixed height of the final window.\n",
    "    \"\"\"\n",
    "    if len(images1) != len(coords1) or len(images2) != len(coords2):\n",
    "        raise ValueError(\"The number of images and coordinates must match for both sets.\")\n",
    "    if len(images1) != len(images2):\n",
    "        raise ValueError(\"Both sets of images must have the same length.\")\n",
    "    \n",
    "    delay = 1 / fps  # Delay in seconds between frames\n",
    "    \n",
    "    # Create a resizable window\n",
    "    window_name = \"Image Viewer\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    for idx, (img1, coord1, img2, coord2) in enumerate(zip(images1, coords1, images2, coords2)):\n",
    "        # Load the images if they are file paths, otherwise assume they are arrays\n",
    "        if isinstance(img1, str):\n",
    "            img1 = cv2.imread(img1)\n",
    "        if isinstance(img2, str):\n",
    "            img2 = cv2.imread(img2)\n",
    "        \n",
    "        # Ensure both images are in the same color space (BGR)\n",
    "        if len(img1.shape) < 3:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) < 3:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Draw markers on each image\n",
    "        if coord1:\n",
    "            cv2.drawMarker(img1, (int(coord1[0]), int(coord1[1])), color=(0, 0, 255), \n",
    "                           markerType=cv2.MARKER_CROSS, thickness=4, markerSize=25)\n",
    "        if coord2:\n",
    "            cv2.drawMarker(img2, (int(coord2[0]), int(coord2[1])), color=(0, 0, 255), \n",
    "                           markerType=cv2.MARKER_TILTED_CROSS, thickness=4, markerSize=25)\n",
    "        # Keep previous marker positions on each subsequent image\n",
    "        for prev_coord1 in coords1[:idx]:\n",
    "            cv2.drawMarker(img1, (int(prev_coord1[0]), int(prev_coord1[1])), color=(0, 255, 0), \n",
    "                   markerType=cv2.MARKER_CROSS, thickness=2, markerSize=15)\n",
    "        for prev_coord2 in coords2[:idx]:\n",
    "            cv2.drawMarker(img2, (int(prev_coord2[0]), int(prev_coord2[1])), color=(0, 255, 0), \n",
    "                   markerType=cv2.MARKER_TILTED_CROSS, thickness=2, markerSize=15)\n",
    "        # Make both images the same height for horizontal concatenation\n",
    "        height = max(img1.shape[0], img2.shape[0])\n",
    "        img1 = cv2.resize(img1, (int(img1.shape[1] * height / img1.shape[0]), height))\n",
    "        img2 = cv2.resize(img2, (int(img2.shape[1] * height / img2.shape[0]), height))\n",
    "        \n",
    "        # Concatenate images horizontally\n",
    "        combined_image = cv2.hconcat([img1, img2])\n",
    "        \n",
    "        # Scale the combined image to have a fixed height\n",
    "        scale_ratio = fixed_height / combined_image.shape[0]\n",
    "        scaled_width = int(combined_image.shape[1] * scale_ratio)\n",
    "        resized_image = cv2.resize(combined_image, (scaled_width, fixed_height))\n",
    "        \n",
    "        # Set the window size to the resized image dimensions\n",
    "        cv2.resizeWindow(window_name, resized_image.shape[1], resized_image.shape[0])\n",
    "        \n",
    "        # Display the resized concatenated image in the window\n",
    "       \n",
    "        # Calculate the position to center the window\n",
    "        window_x = 1400\n",
    "        window_y = 50\n",
    "        \n",
    "        # Move the window to the center of the screen\n",
    "        cv2.moveWindow(window_name, window_x, window_y)\n",
    "        \n",
    "        cv2.imshow(window_name, resized_image)\n",
    "        \n",
    "        # Wait for the specified delay or until a key is pressed\n",
    "        if idx == len(images1) - 1:\n",
    "            # Keep the last image displayed until the user closes the window\n",
    "            print(\"Final image displayed. Close the window to end.\")\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(int(delay * 1000))  # Convert delay to milliseconds\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def display_images_with_graph(images1, coords1, images2, coords2, graph_data, fps=2, fixed_height=600, save_video=False, output_path=\"output_video.mp4\"):\n",
    "    \"\"\"\n",
    "    Display two sets of images side by side with a live-updating graph below them, \n",
    "    and optionally save the sequence as a video.\n",
    "\n",
    "    Parameters:\n",
    "        images1 (list): First set of images (file paths or image arrays).\n",
    "        coords1 (list): Coordinates for the first set of images (list of (x, y) tuples).\n",
    "        images2 (list): Second set of images (file paths or image arrays).\n",
    "        coords2 (list): Coordinates for the second set of images (list of (x, y) tuples).\n",
    "        graph_data (list): List of (x, y) tuples for graph plotting.\n",
    "        fps (int): Frames per second for image display.\n",
    "        fixed_height (int): Fixed height of the final display window.\n",
    "        save_video (bool): Whether to save the sequence as a video.\n",
    "        output_path (str): Path to save the video (if enabled).\n",
    "    \"\"\"\n",
    "    if len(images1) != len(coords1) or len(images2) != len(coords2) or len(images1) != len(graph_data):\n",
    "        raise ValueError(\"The number of images, coordinates, and graph data points must match.\")\n",
    "    \n",
    "    delay = 1 / fps  # Delay in seconds between frames\n",
    "    \n",
    "    # Create a resizable window\n",
    "    window_name = \"Image Viewer\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # Initialize video writer if saving the video\n",
    "    video_writer = None\n",
    "    if save_video:\n",
    "        frame_width = 2 * fixed_height  # Assuming width proportional to height\n",
    "        frame_height = int(fixed_height + fixed_height * 0.6)  # Extra height for graph\n",
    "        video_writer = cv2.VideoWriter(\n",
    "            output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "            fps,\n",
    "            (frame_width, frame_height)\n",
    "        )\n",
    "    \n",
    "    for idx, (img1, coord1, img2, coord2, (x_vals, y_vals)) in enumerate(zip(images1, coords1, images2, coords2, graph_data)):\n",
    "        # Load the images if they are file paths, otherwise assume they are arrays\n",
    "        if isinstance(img1, str):\n",
    "            img1 = cv2.imread(img1)\n",
    "        if isinstance(img2, str):\n",
    "            img2 = cv2.imread(img2)\n",
    "        \n",
    "        # Ensure both images are in the same color space (BGR)\n",
    "        if len(img1.shape) < 3:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) < 3:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Draw markers on each image\n",
    "        if coord1:\n",
    "            cv2.drawMarker(img1, (int(coord1[0]), int(coord1[1])), color=(0, 0, 255), \n",
    "                           markerType=cv2.MARKER_CROSS, thickness=3, markerSize=50)\n",
    "        if coord2:\n",
    "            cv2.drawMarker(img2, (int(coord2[0]), int(coord2[1])), color=(0, 0, 255), \n",
    "                           markerType=cv2.MARKER_TILTED_CROSS, thickness=3, markerSize=50)\n",
    "        # Keep previous marker positions on each subsequent image\n",
    "        for prev_coord1 in coords1[:idx]:\n",
    "            cv2.drawMarker(img1, (int(prev_coord1[0]), int(prev_coord1[1])), color=(255, 0, 0), \n",
    "                   markerType=cv2.MARKER_CROSS, thickness=2, markerSize=40)\n",
    "        for prev_coord2 in coords2[:idx]:\n",
    "            cv2.drawMarker(img2, (int(prev_coord2[0]), int(prev_coord2[1])), color=(255, 0, 0), \n",
    "                   markerType=cv2.MARKER_TILTED_CROSS, thickness=2, markerSize=40)\n",
    "            \n",
    "        # Resize images to the fixed height\n",
    "        height = fixed_height\n",
    "        img1 = cv2.resize(img1, (int(img1.shape[1] * height / img1.shape[0]), height))\n",
    "        img2 = cv2.resize(img2, (int(img2.shape[1] * height / img2.shape[0]), height))\n",
    "        \n",
    "        # Concatenate images horizontally\n",
    "        combined_image = cv2.hconcat([img1, img2])\n",
    "        \n",
    "        # Create the graph as an image\n",
    "        fig, ax = plt.subplots(figsize=(4, 3))\n",
    "        max_x = max(graph_data, key=lambda x: x[0])[0]\n",
    "        max_y = max(graph_data, key=lambda x: x[1])[1]\n",
    "        ax.set_xlim([0, max_x * 1.1])\n",
    "        ax.set_ylim([0, max_y * 1.1])\n",
    "        ax.plot(x_vals, y_vals, marker=\"o\", color=\"blue\", linewidth=2)\n",
    "        # for prev_xy in graph_data[:idx]:\n",
    "        for prev_x_vals, prev_y_vals in graph_data[:idx]:\n",
    "            ax.plot(prev_x_vals, prev_y_vals,  marker=\"o\", color=\"black\", linewidth=2)\n",
    "        ax.set_xlabel(\"t(sec)\")\n",
    "        ax.set_ylabel(\"F(N)\")\n",
    "        ax.grid(True)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.draw()\n",
    "        graph_img = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "        graph_img = graph_img.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Resize the graph to match the combined image width\n",
    "        graph_height = int(combined_image.shape[0] * 0.5)  # Scale graph height relative to images\n",
    "        graph_img = cv2.resize(graph_img, (combined_image.shape[1], graph_height))\n",
    "        \n",
    "        # Concatenate graph below the images\n",
    "        final_frame = cv2.vconcat([combined_image, graph_img])\n",
    "        \n",
    "        # Resize window to match final frame dimensions\n",
    "        cv2.resizeWindow(window_name, final_frame.shape[1], final_frame.shape[0])\n",
    "        \n",
    "        # Calculate the position to center the window\n",
    "        window_x = 100\n",
    "        window_y = 50\n",
    "        \n",
    "        # Move the window to the center of the screen\n",
    "        cv2.moveWindow(window_name, window_x, window_y)\n",
    "        \n",
    "        # Display the final frame\n",
    "        cv2.imshow(window_name, final_frame)\n",
    "        \n",
    "        # Write to video if saving\n",
    "        if save_video and video_writer:\n",
    "            video_writer.write(cv2.cvtColor(final_frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Wait for the specified delay or until a key is pressed\n",
    "        if idx == len(images1) - 1:\n",
    "            # Keep the last frame displayed until the user closes the window\n",
    "            print(\"Final frame displayed. Close the window to end.\")\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(int(delay * 1000))  # Convert delay to milliseconds\n",
    "    \n",
    "    # Release the video writer\n",
    "    if save_video and video_writer:\n",
    "        video_writer.release()\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def display_images_with_graph2(\n",
    "    images1, coords1, images2, coords2, graph_data, fps=2, fixed_height=600, save_video=False, output_path=\"output_video.mp4\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Display two sets of images side by side with a live-updating graph below them,\n",
    "    and optionally save the sequence as a video.\n",
    "\n",
    "    Parameters:\n",
    "        images1 (list): First set of images (file paths or image arrays).\n",
    "        coords1 (list): Coordinates for the first set of images (list of (x, y) tuples).\n",
    "        images2 (list): Second set of images (file paths or image arrays).\n",
    "        coords2 (list): Coordinates for the second set of images (list of (x, y) tuples).\n",
    "        graph_data (list): List of (x, y) tuples for graph plotting.\n",
    "        fps (int): Frames per second for image display.\n",
    "        fixed_height (int): Fixed height of the final display window.\n",
    "        save_video (bool): Whether to save the sequence as a video.\n",
    "        output_path (str): Path to save the video (if enabled).\n",
    "    \"\"\"\n",
    "    if len(images1) != len(coords1) or len(images2) != len(coords2) or len(images1) != len(graph_data):\n",
    "        raise ValueError(\"The number of images, coordinates, and graph data points must match.\")\n",
    "\n",
    "    delay = 1 / fps  # Delay in seconds between frames\n",
    "\n",
    "    # Create a resizable window\n",
    "    window_name = \"Image Viewer\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Initialize video writer if saving the video\n",
    "    video_writer = None\n",
    "    frame_width = 2 * fixed_height  # Width proportional to height\n",
    "    frame_height = int(fixed_height + 200)  # Extra height for graph\n",
    "    if save_video:\n",
    "        video_writer = cv2.VideoWriter(\n",
    "            output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "            fps,\n",
    "            (frame_width, frame_height),\n",
    "        )\n",
    "\n",
    "    for idx, (img1, coord1, img2, coord2, (x_vals, y_vals)) in enumerate(zip(images1, coords1, images2, coords2, graph_data)):\n",
    "        # Load the images if they are file paths, otherwise assume they are arrays\n",
    "        if isinstance(img1, str):\n",
    "            img1 = cv2.imread(img1)\n",
    "        if isinstance(img2, str):\n",
    "            img2 = cv2.imread(img2)\n",
    "\n",
    "        # Ensure both images are in the same color space (BGR)\n",
    "        if len(img1.shape) < 3:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) < 3:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Draw markers on each image\n",
    "        if coord1:\n",
    "            cv2.drawMarker(img1, (int(coord1[0]), int(coord1[1])), color=(0, 0, 255),\n",
    "                           markerType=cv2.MARKER_CROSS, thickness=3, markerSize=45)\n",
    "        if coord2:\n",
    "            cv2.drawMarker(img2, (int(coord2[0]), int(coord2[1])), color=(0, 0, 255),\n",
    "                           markerType=cv2.MARKER_TILTED_CROSS, thickness=3, markerSize=45)\n",
    "        # Keep previous marker positions on each subsequent image\n",
    "        for prev_coord1 in coords1[:idx]:\n",
    "            cv2.drawMarker(img1, (int(prev_coord1[0]), int(prev_coord1[1])), color=(255, 0, 0), \n",
    "                   markerType=cv2.MARKER_CROSS, thickness=2, markerSize=40)\n",
    "        for prev_coord2 in coords2[:idx]:\n",
    "            cv2.drawMarker(img2, (int(prev_coord2[0]), int(prev_coord2[1])), color=(255, 0, 0), \n",
    "                   markerType=cv2.MARKER_TILTED_CROSS, thickness=2, markerSize=40)\n",
    "            \n",
    "        # Resize images to the fixed height\n",
    "        height = fixed_height\n",
    "        img1 = cv2.resize(img1, (int(img1.shape[1] * height / img1.shape[0]), height))\n",
    "        img2 = cv2.resize(img2, (int(img2.shape[1] * height / img2.shape[0]), height))\n",
    "\n",
    "        # Concatenate images horizontally\n",
    "        combined_image = cv2.hconcat([img1, img2])\n",
    "\n",
    "        # Create the graph as an image\n",
    "        fig, ax = plt.subplots(figsize=(8, 2))  # Fixed aspect ratio\n",
    "        ax.plot(x_vals, y_vals, marker=\"o\", color=\"blue\", linewidth=2)\n",
    "        for prev_x_vals, prev_y_vals in graph_data[:idx]:\n",
    "            ax.plot(prev_x_vals, prev_y_vals, marker=\"o\", color=\"black\", linewidth=2)\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Force (N)\")\n",
    "        max_x = max(graph_data, key=lambda x: x[0])[0]\n",
    "        max_y = max(graph_data, key=lambda x: x[1])[1]\n",
    "        ax.set_xlim([0, max_x * 1.1])\n",
    "        ax.set_ylim([0, max_y * 1.1])\n",
    "        ax.grid(True)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.draw()\n",
    "        graph_img = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n",
    "        graph_img = graph_img.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Resize the graph to match the width of the combined image\n",
    "        graph_img = cv2.resize(graph_img, (combined_image.shape[1], 200))\n",
    "        # Convert graph image to RGB\n",
    "        graph_img = cv2.cvtColor(graph_img, cv2.COLOR_BGR2RGB)\n",
    "        # Concatenate graph below the images\n",
    "        final_frame = cv2.vconcat([combined_image, graph_img])\n",
    "\n",
    "        # Convert to BGR for OpenCV and ensure dimensions match and return to RBG\n",
    "        # final_frame_bgr = cv2.cvtColor(final_frame, cv2.COLOR_RGB2BGR)\n",
    "        # final_frame = cv2.cvtColor(final_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize window to match final frame dimensions\n",
    "        # cv2.resizeWindow(window_name, final_frame_bgr.shape[1], final_frame_bgr.shape[0])\n",
    "        cv2.resizeWindow(window_name, final_frame.shape[1], final_frame.shape[0])\n",
    "\n",
    "        # Display the final frame\n",
    "        # cv2.imshow(window_name, final_frame_bgr)\n",
    "        cv2.imshow(window_name, final_frame)\n",
    "       \n",
    "        if video_writer is None and save_video:\n",
    "            # frame_width, frame_height = final_frame_bgr.shape[1], final_frame_bgr.shape[0]\n",
    "            frame_width, frame_height = final_frame.shape[1], final_frame.shape[0]\n",
    "            video_writer = cv2.VideoWriter(\n",
    "                output_path,\n",
    "                cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "                fps,\n",
    "                (frame_width, frame_height),\n",
    "            )\n",
    "\n",
    "        if save_video and video_writer:\n",
    "            # final_frame_resized = cv2.resize(final_frame_bgr, (frame_width, frame_height))\n",
    "            final_frame_resized = cv2.resize(final_frame, (frame_width, frame_height))\n",
    "            video_writer.write(final_frame_resized)\n",
    "\n",
    "        # cv2.resizeWindow(window_name, final_frame_bgr.shape[1], final_frame_bgr.shape[0])\n",
    "        cv2.resizeWindow(window_name, final_frame.shape[1], final_frame.shape[0])\n",
    "        # cv2.imshow(window_name, final_frame_bgr)\n",
    "        cv2.imshow(window_name, final_frame)\n",
    "\n",
    "        if idx == len(images1) - 1:\n",
    "            print(\"Final frame displayed. Close the window to end.\")\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            cv2.waitKey(int(delay * 1000))\n",
    "\n",
    "    if save_video and video_writer:\n",
    "        video_writer.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 2\n",
      "11 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_26152\\1567752453.py:314: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  graph_img = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1473: error: (-27:Null pointer) NULL window: 'Image Viewer' in function 'cvResizeWindow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m force_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(t,event\u001b[38;5;241m.\u001b[39mF_bean[event\u001b[38;5;241m.\u001b[39mfrm0_top:event\u001b[38;5;241m.\u001b[39mfrm_dec_top][:fr]))\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# parallel_video(top_images, top_xy_coor,side_images, side_xz_coor, fps=2)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mdisplay_images_with_graph2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_xy_coor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mside_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside_xz_coor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfixed_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_video\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvid_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mside_top_f(t)_video.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 331\u001b[0m, in \u001b[0;36mdisplay_images_with_graph2\u001b[1;34m(images1, coords1, images2, coords2, graph_data, fps, fixed_height, save_video, output_path)\u001b[0m\n\u001b[0;32m    323\u001b[0m final_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mvconcat([combined_image, graph_img])\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# Convert to BGR for OpenCV and ensure dimensions match and return to RBG\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# final_frame_bgr = cv2.cvtColor(final_frame, cv2.COLOR_RGB2BGR)\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# final_frame = cv2.cvtColor(final_frame, cv2.COLOR_BGR2RGB)\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Resize window to match final frame dimensions\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# cv2.resizeWindow(window_name, final_frame_bgr.shape[1], final_frame_bgr.shape[0])\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresizeWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# Display the final frame\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# cv2.imshow(window_name, final_frame_bgr)\u001b[39;00m\n\u001b[0;32m    335\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(window_name, final_frame)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1473: error: (-27:Null pointer) NULL window: 'Image Viewer' in function 'cvResizeWindow'\n"
     ]
    }
   ],
   "source": [
    "#%%  Define the experiment and event numbers\n",
    "# exp_num = 30\n",
    "# event_num = 1\n",
    "# find the event corresponding to exp_num and event_num:\n",
    "\n",
    "i = 70 # 40 (simple) , 20,120 (bump from dist2tip), i=70->event 79_2\n",
    "event = events[i]\n",
    "print(event.p.exp_num,event.event_num)\n",
    "print(event.frm0_top,event.frm_dec_top)\n",
    "\n",
    "# start video from initial contact frame for both views\n",
    "\n",
    "# Define paths to the video frames\n",
    "side_view_path = r\"C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Data\\sample trajectory\\79_2_side\"\n",
    "top_view_path = r\"C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Data\\sample trajectory\\79_2_top\"\n",
    "vid_path = r\"C:\\Users\\Amir\\Documents\\PHD\\Thesis\\My Articles\\0 - Flexible dynamic force measurement method via physical pendulum\\Data\\sample trajectory\"\n",
    "\n",
    "top_view_files = [os.path.join(top_view_path, f) for f in os.listdir(top_view_path) if os.path.isfile(os.path.join(top_view_path, f))]\n",
    "side_view_files = [os.path.join(side_view_path, f) for f in os.listdir(side_view_path) if os.path.isfile(os.path.join(side_view_path, f))]                                                                    \n",
    "\n",
    "# Define the number of frames\n",
    "fr = 50\n",
    "fr = min(fr,len(top_view_files))\n",
    "\n",
    "# top images and tracked coordiantes\n",
    "top_images = top_view_files[event.frm0_top:event.frm_dec_top][:fr]\n",
    "dec_x_track_top = event.x_track_top0[event.frm0_top:event.frm_dec_top][:fr]\n",
    "dec_y_track_top = event.y_track_top0[event.frm0_top:event.frm_dec_top][:fr]\n",
    "top_xy_coor = list(zip(dec_x_track_top,dec_y_track_top))\n",
    "\n",
    "# side images and tracked coordiantes\n",
    "side_images = side_view_files[event.frm0_side:event.frm_dec_side][:fr]\n",
    "dec_x_track_side = event.x_track_side0[event.frm0_side:event.frm_dec_side][:fr]\n",
    "dec_y_track_side = event.z_track_side0[event.frm0_side:event.frm_dec_side][:fr]\n",
    "side_xz_coor = list(zip(dec_x_track_side,dec_y_track_side))\n",
    "t = event.timer[event.frm0_top:event.frm_dec_top][:fr]-event.timer[event.frm0_top]\n",
    "# force data\n",
    "force_data = list(zip(t,event.F_bean[event.frm0_top:event.frm_dec_top][:fr]))\n",
    "\n",
    "# parallel_video(top_images, top_xy_coor,side_images, side_xz_coor, fps=2)\n",
    "display_images_with_graph2(top_images, top_xy_coor,side_images, side_xz_coor, graph_data=force_data , fps=5,\n",
    "                          fixed_height=300, save_video=False, output_path=vid_path+\"\\\\side_top_f(t)_video.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
